{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762eaecd",
   "metadata": {},
   "source": [
    "## Chapter 10 - Implementing MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a6eaa",
   "metadata": {},
   "source": [
    "### Question 10 - fitting MLP on Mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96017539",
   "metadata": {},
   "source": [
    "this exercise was to train MLP on the Mnist dataset and try to achieve 98% accuracy on the test set. \n",
    "the main point here is to find the best learning rate - by starting with a very small learning rate and growing it larger\n",
    "by some factor each iteration on batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ce4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df17dd6",
   "metadata": {},
   "source": [
    "making log dirs to use later in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d04953",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_logdir = os.path.join(os.getcwd() , \"my_logs\")\n",
    "\n",
    "def create_run_log():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(git_logdir , run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91ae73",
   "metadata": {},
   "source": [
    "loading the data, splitting the training set into training and validation, and scaling the inputs into 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3caf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train) , (X_test , y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2635a72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc06c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test = X_train/255.0 , X_test/255.0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_val , y_train , y_val = train_test_split(X_train , y_train , train_size=50000 , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28aca70",
   "metadata": {},
   "source": [
    "building a learning rate/callbacks class which each iteraion on batch end setting the new learning rate by multiplying \n",
    "the last one by some factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe34a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_lr(keras.callbacks.Callback):\n",
    "    def __init__(self,factor):\n",
    "        self.factor = factor\n",
    "        self.loss = []\n",
    "        self.lr = []\n",
    "    def on_batch_end(self , batch , logs):\n",
    "        self.lr.append(keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        self.loss.append(logs[\"loss\"])\n",
    "        keras.backend.set_value(self.model.optimizer.learning_rate , self.model.optimizer.learning_rate * self.factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81ca68b",
   "metadata": {},
   "source": [
    "building the models. we have a flattening layer, and 3 dense layer which the last one is the output layer.\n",
    "here we chose this factor in out learning rate class in order to start with 10^-5 learning rate and finishing with 10 leaning rate after 500 iterations(this is the reason i chose batch_size = 100).\n",
    "we then compile the model and fitting it on the training set using 1 ecpoh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482deb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 2ms/step - loss: 547425144785840426188800.0000 - accuracy: 0.2974 - val_loss: 30.9075 - val_accuracy: 0.1010\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100 , activation = \"relu\"),\n",
    "    keras.layers.Dense(10 , activation = \"softmax\")\n",
    "])\n",
    "\n",
    "expo_lr = my_lr(np.exp(np.log(10**6)/500))\n",
    "run_log = create_run_log()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = keras.optimizers.SGD(10e-5) ,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , batch_size=100 , epochs=1 , validation_data=(X_val , y_val),\n",
    "                   callbacks=[expo_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd61fb",
   "metadata": {},
   "source": [
    "plotting the loss vs learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391ce71e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expo_lr.lr , expo_lr.loss)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expo_lr.loss), min(expo_lr.lr), max(expo_lr.lr))\n",
    "plt.axis([min(expo_lr.lr), max(expo_lr.lr), 0, expo_lr.loss[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5bd25",
   "metadata": {},
   "source": [
    "finding the best learning rate. here i divided the learning rate by 3 because it was close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35643123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588254451751709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss_for_lr = expo_lr.lr[np.argmin(expo_lr.loss)]/3\n",
    "min_loss_for_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08215857",
   "metadata": {},
   "source": [
    "refitting the model with the new learning rate, and adding early stopping callback with patience = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573308b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1563 [..............................] - ETA: 0s - loss: 2.3378 - accuracy: 0.1562WARNING:tensorflow:From C:\\Users\\itay\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0174s). Check your callbacks.\n",
      "1563/1563 [==============================] - 1s 798us/step - loss: 0.2423 - accuracy: 0.9232 - val_loss: 0.1319 - val_accuracy: 0.9604\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 1s 699us/step - loss: 0.0977 - accuracy: 0.9694 - val_loss: 0.0953 - val_accuracy: 0.9717\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 1s 669us/step - loss: 0.0679 - accuracy: 0.9780 - val_loss: 0.1606 - val_accuracy: 0.9554\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 1s 671us/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 0.0852 - val_accuracy: 0.9747\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 1s 692us/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0880 - val_accuracy: 0.9765\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 1s 671us/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.0897 - val_accuracy: 0.9764\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 1s 692us/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0802 - val_accuracy: 0.9801\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 1s 673us/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0860 - val_accuracy: 0.9801\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 1s 710us/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0914 - val_accuracy: 0.9794\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 1s 687us/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.0920 - val_accuracy: 0.9785\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 1s 675us/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.1076 - val_accuracy: 0.9787\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 1s 708us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0883 - val_accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = [28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100 , activation = \"relu\"),\n",
    "    keras.layers.Dense(10 , activation = \"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "run_log = create_run_log()\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = keras.optimizers.SGD(min_loss_for_lr) ,\n",
    "             metrics=[\"accuracy\"])\n",
    "cb_tensorboard = keras.callbacks.TensorBoard(run_log)\n",
    "cb_early_stopping = keras.callbacks.EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(X_train , y_train  , epochs=100 , validation_data=(X_val , y_val),\n",
    "                   callbacks=[cb_early_stopping , cb_tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef107a3",
   "metadata": {},
   "source": [
    "and this is it, we build a model that achieved 97.7% accuracy on the test set, using very basic model and just searching \n",
    "for the best learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d183bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 424us/step - loss: 0.0953 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0952892005443573, 0.9778000116348267]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
