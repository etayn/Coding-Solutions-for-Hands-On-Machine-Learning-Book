{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f09f2a4",
   "metadata": {},
   "source": [
    "## Chapter 11 - Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69ff2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d69f6",
   "metadata": {},
   "source": [
    "loading CIFAR10 dataset and splitting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ab54f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train , y_train) , (X_test , y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ea2f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (10000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train , X_val , y_train , y_val = train_test_split(X_train , y_train , train_size=40000 , random_state=42)\n",
    "print(X_train.shape , X_val.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857cf64c",
   "metadata": {},
   "source": [
    "building DNN with 20 hidden layers of 100 neurons at each layer, using He initialization, ELU activation and nadam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e6240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3))\n",
    "])\n",
    "for layer in range(20):\n",
    "    model.add(keras.layers.Dense(100 , kernel_initializer = \"he_normal\" ,\n",
    "                                activation = 'elu'))\n",
    "\n",
    "model.add(keras.layers.Dense(10 , activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d44236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               307300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1828f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(patience=5)\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = \"nadam\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fd6113",
   "metadata": {},
   "source": [
    "training the DNN with early stopping, we got 1.6636 val_loss and 0.3944 accuracy on the validation set after 26 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "289cc879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 5.0356 - accuracy: 0.1984 - val_loss: 1.9532 - val_accuracy: 0.2793\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.9701 - accuracy: 0.2797 - val_loss: 1.9612 - val_accuracy: 0.2904\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8991 - accuracy: 0.3043 - val_loss: 1.8455 - val_accuracy: 0.3322\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8611 - accuracy: 0.3211 - val_loss: 1.9038 - val_accuracy: 0.2934\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8395 - accuracy: 0.3319 - val_loss: 1.8445 - val_accuracy: 0.3246\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 1.8280 - accuracy: 0.3343 - val_loss: 1.8000 - val_accuracy: 0.3417\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8163 - accuracy: 0.3404 - val_loss: 1.8223 - val_accuracy: 0.3428\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8134 - accuracy: 0.3393 - val_loss: 1.8253 - val_accuracy: 0.3368\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 1.8016 - accuracy: 0.3440 - val_loss: 1.8512 - val_accuracy: 0.3156\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7869 - accuracy: 0.3519 - val_loss: 1.8062 - val_accuracy: 0.3517\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7750 - accuracy: 0.3543 - val_loss: 1.7784 - val_accuracy: 0.3530\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7586 - accuracy: 0.3579 - val_loss: 1.7885 - val_accuracy: 0.3448\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7494 - accuracy: 0.3587 - val_loss: 1.7495 - val_accuracy: 0.3641\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7437 - accuracy: 0.3643 - val_loss: 1.8655 - val_accuracy: 0.3294\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7292 - accuracy: 0.3641 - val_loss: 1.7534 - val_accuracy: 0.3626\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7172 - accuracy: 0.3726 - val_loss: 1.7275 - val_accuracy: 0.3636\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7088 - accuracy: 0.3717 - val_loss: 1.7348 - val_accuracy: 0.3634\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.7011 - accuracy: 0.3790 - val_loss: 1.7482 - val_accuracy: 0.3552\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.6922 - accuracy: 0.3819 - val_loss: 1.7268 - val_accuracy: 0.3632\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6820 - accuracy: 0.3825 - val_loss: 1.7177 - val_accuracy: 0.3654\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6745 - accuracy: 0.3869 - val_loss: 1.7078 - val_accuracy: 0.3810\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6674 - accuracy: 0.3945 - val_loss: 1.6869 - val_accuracy: 0.3778\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 1.6574 - accuracy: 0.4006 - val_loss: 1.6769 - val_accuracy: 0.3906\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6453 - accuracy: 0.4040 - val_loss: 1.6707 - val_accuracy: 0.3873\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6393 - accuracy: 0.4090 - val_loss: 1.6733 - val_accuracy: 0.3984\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6342 - accuracy: 0.4090 - val_loss: 1.6636 - val_accuracy: 0.3944\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6269 - accuracy: 0.4115 - val_loss: 1.6722 - val_accuracy: 0.3966\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6230 - accuracy: 0.4134 - val_loss: 1.6736 - val_accuracy: 0.3937\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6185 - accuracy: 0.4168 - val_loss: 1.6934 - val_accuracy: 0.3959\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6975 - accuracy: 0.3799 - val_loss: 1.7184 - val_accuracy: 0.3700\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6617 - accuracy: 0.3952 - val_loss: 1.6853 - val_accuracy: 0.3866\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train , y_train , validation_data=(X_val, y_val) , callbacks=[early_stop] ,\n",
    "                    epochs = 50 , batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ce29e8",
   "metadata": {},
   "source": [
    "training the DNN model but this time adding batch normalization after each Dense layer and the Input layer, before activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe610755",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)) ,\n",
    "    keras.layers.BatchNormalization()\n",
    "])\n",
    "for layer in range(20):\n",
    "    model2.add(keras.layers.Dense(100 , kernel_initializer = \"he_normal\"))\n",
    "    model2.add(keras.layers.BatchNormalization())\n",
    "    model2.add(keras.layers.Activation(\"elu\"))\n",
    "               \n",
    "model2.add(keras.layers.Dense(10 , activation = \"softmax\"))\n",
    "               \n",
    "model2.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = \"nadam\" , metrics=[\"accuracy\"])               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecafbf2f",
   "metadata": {},
   "source": [
    "training the DNN, we got 1.3837 val_loss and 0.5299 val accuracy after 16 epochs, so the model is performing much better and faster after using batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95aafcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.7932 - accuracy: 0.3579 - val_loss: 1.7142 - val_accuracy: 0.3974\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.6039 - accuracy: 0.4273 - val_loss: 1.5725 - val_accuracy: 0.4383\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.5275 - accuracy: 0.4564 - val_loss: 1.5661 - val_accuracy: 0.4544\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.4670 - accuracy: 0.4769 - val_loss: 1.5230 - val_accuracy: 0.4614\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.4210 - accuracy: 0.4911 - val_loss: 1.4772 - val_accuracy: 0.4805\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.3781 - accuracy: 0.5112 - val_loss: 1.4484 - val_accuracy: 0.4903\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.3410 - accuracy: 0.5225 - val_loss: 1.4194 - val_accuracy: 0.5072\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.3113 - accuracy: 0.5339 - val_loss: 1.4437 - val_accuracy: 0.4849\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.2832 - accuracy: 0.5443 - val_loss: 1.4262 - val_accuracy: 0.4991\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.2510 - accuracy: 0.5554 - val_loss: 1.4242 - val_accuracy: 0.5032\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.2275 - accuracy: 0.5639 - val_loss: 1.3942 - val_accuracy: 0.5173\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.2037 - accuracy: 0.5743 - val_loss: 1.4146 - val_accuracy: 0.5157\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.1771 - accuracy: 0.5848 - val_loss: 1.4409 - val_accuracy: 0.5019\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.1588 - accuracy: 0.5911 - val_loss: 1.3985 - val_accuracy: 0.5151\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.1371 - accuracy: 0.5981 - val_loss: 1.3990 - val_accuracy: 0.5216\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.1152 - accuracy: 0.6050 - val_loss: 1.3837 - val_accuracy: 0.5299\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.0974 - accuracy: 0.6116 - val_loss: 1.4169 - val_accuracy: 0.5191\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.0769 - accuracy: 0.6205 - val_loss: 1.5132 - val_accuracy: 0.5036\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.0508 - accuracy: 0.6295 - val_loss: 1.4113 - val_accuracy: 0.5251\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 6s 10ms/step - loss: 1.0451 - accuracy: 0.6300 - val_loss: 1.4157 - val_accuracy: 0.5263\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.0184 - accuracy: 0.6402 - val_loss: 1.4208 - val_accuracy: 0.5306\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train,y_train,validation_data=(X_val,y_val) , batch_size = 64,epochs = 50 , \n",
    "                     callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e829c",
   "metadata": {},
   "source": [
    "this time we will use self-normalize DNN, so we standardize the inputs, we use lecun initialization and SELU activation function (and the DNN is sequential)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "X_train_stand = (X_train - X_mean) / X_std\n",
    "X_val_stand= (X_val - X_mean) / X_std\n",
    "X_test_stand = (X_test - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c02068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)) ,\n",
    "])\n",
    "for layer in range(20):\n",
    "    model3.add(keras.layers.Dense(100 , kernel_initializer = \"lecun_normal\" , activation = \"selu\"))\n",
    "               \n",
    "model3.add(keras.layers.Dense(10 , activation = \"softmax\"))\n",
    "               \n",
    "model3.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = \"nadam\" , metrics=[\"accuracy\"])               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653501b6",
   "metadata": {},
   "source": [
    "training the DNN, we got 1.4888 val_loss and 0.4906 val accuracy after 14 epcohs, so this DNN performing rather similary to the DNN with batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02f3b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.9459 - accuracy: 0.3033 - val_loss: 1.7762 - val_accuracy: 0.3630\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7292 - accuracy: 0.3821 - val_loss: 1.7289 - val_accuracy: 0.3858\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6252 - accuracy: 0.4245 - val_loss: 1.6940 - val_accuracy: 0.3897\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.5518 - accuracy: 0.4544 - val_loss: 1.6360 - val_accuracy: 0.4238\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.4975 - accuracy: 0.4740 - val_loss: 1.5687 - val_accuracy: 0.4496\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.4480 - accuracy: 0.4915 - val_loss: 1.5656 - val_accuracy: 0.4590\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.3999 - accuracy: 0.5125 - val_loss: 1.5920 - val_accuracy: 0.4484\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.3649 - accuracy: 0.5271 - val_loss: 1.5345 - val_accuracy: 0.4674\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.3240 - accuracy: 0.5415 - val_loss: 1.5248 - val_accuracy: 0.4753\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.2919 - accuracy: 0.5512 - val_loss: 1.5274 - val_accuracy: 0.4842\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.2614 - accuracy: 0.5630 - val_loss: 1.5176 - val_accuracy: 0.4805\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.2323 - accuracy: 0.5729 - val_loss: 1.5115 - val_accuracy: 0.4858\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.2030 - accuracy: 0.5860 - val_loss: 1.4985 - val_accuracy: 0.4940\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.1871 - accuracy: 0.5947 - val_loss: 1.4888 - val_accuracy: 0.4906\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.1557 - accuracy: 0.6040 - val_loss: 1.5170 - val_accuracy: 0.4869\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.1286 - accuracy: 0.6185 - val_loss: 1.5088 - val_accuracy: 0.4892\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.1091 - accuracy: 0.6224 - val_loss: 1.4996 - val_accuracy: 0.4974\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.0956 - accuracy: 0.6274 - val_loss: 1.4997 - val_accuracy: 0.5053\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.0565 - accuracy: 0.6430 - val_loss: 1.5571 - val_accuracy: 0.4988\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(X_train_stand , y_train , validation_data=(X_val_stand , y_val) , batch_size = 64 , epochs = 50,\n",
    "                     callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988dbdfd",
   "metadata": {},
   "source": [
    "adding to the previous DNN Alphadropout layers with ratio of 0.1 after Dense layers (Alphadropout works in self-normalize networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec23b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (32,32,3)) ,\n",
    "])\n",
    "for layer in range(20):\n",
    "    model4.add(keras.layers.Dense(100 , kernel_initializer = \"lecun_normal\" , activation = \"selu\"))\n",
    "    model4.add(keras.layers.AlphaDropout(0.1,seed=42))\n",
    "               \n",
    "model4.add(keras.layers.Dense(10 , activation = \"softmax\"))\n",
    "               \n",
    "model4.compile(loss = \"sparse_categorical_crossentropy\" , optimizer = \"nadam\" , metrics=[\"accuracy\"])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813f6c8",
   "metadata": {},
   "source": [
    "training the DNN, we got 1.9014 val_loss and 0.3631 val accuracy after 5 epochs, the model converges much faster when using rather small early stopping patience, but with worst results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a52fb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 2.1529 - accuracy: 0.2088 - val_loss: 2.1552 - val_accuracy: 0.2794\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.9100 - accuracy: 0.2782 - val_loss: 2.0083 - val_accuracy: 0.3167\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.8396 - accuracy: 0.3147 - val_loss: 2.0315 - val_accuracy: 0.3256\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7819 - accuracy: 0.3405 - val_loss: 1.9577 - val_accuracy: 0.3696\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7492 - accuracy: 0.3577 - val_loss: 1.9014 - val_accuracy: 0.3631\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7146 - accuracy: 0.3724 - val_loss: 2.0499 - val_accuracy: 0.3825\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6975 - accuracy: 0.3819 - val_loss: 1.9603 - val_accuracy: 0.3586\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6857 - accuracy: 0.3862 - val_loss: 2.3105 - val_accuracy: 0.3611\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.7003 - accuracy: 0.3828 - val_loss: 2.3453 - val_accuracy: 0.3863\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 1.6672 - accuracy: 0.3909 - val_loss: 2.4277 - val_accuracy: 0.3861\n"
     ]
    }
   ],
   "source": [
    "history4 = model4.fit(X_train_stand , y_train , validation_data=(X_val_stand , y_val) , batch_size = 64 , epochs = 50,\n",
    "                     callbacks=[early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
