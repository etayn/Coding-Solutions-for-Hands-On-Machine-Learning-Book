{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ceaae3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd263800",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNormLayer(keras.layers.Layer):\n",
    "    def __init__(self , **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        self.alpha = self.add_weight(name = \"alpha\" , shape=input_shape[-1:] , dtype=tf.float32,\n",
    "                                    initializer=keras.initializers.Ones)\n",
    "        self.beta = self.add_weight(name = \"beta\" , shape=input_shape[-1:] , dtype=tf.float32,\n",
    "                                   initializer=keras.initializers.Zeros)\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self,X):\n",
    "        mu , var = tf.nn.moments(X , axes=-1 , keepdims=True)\n",
    "        sigma = tf.sqrt(var)\n",
    "        return (self.alpha*(X-mu)/(sigma + 0.001)) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897fd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3194285",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train , y_train) , (X_test , y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d13bcf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255 \n",
    "X_test =  X_test.astype(\"float32\") / 255\n",
    "X_train , X_val , y_train , y_val = train_test_split(X_train , y_train , train_size=0.8)\n",
    "training_data = tf.data.Dataset.from_tensor_slices((X_train , y_train)).batch(32)\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((X_val , y_val)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5d73f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(28,28))\n",
    "    flatten = keras.layers.Flatten()(inputs)\n",
    "    x = keras.layers.Dense(512 , activation = \"relu\")(flatten)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    x = keras.layers.Dense(100 , activation = \"relu\")(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    output = keras.layers.Dense(10 , activation = \"softmax\")(x)\n",
    "    model = keras.Model(inputs , output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1cf0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d0e726bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of epoch 1:\n",
      " => sparse_categorical_accuracy : 0.8760\n",
      " => loss : 0.3356\n",
      " => val_sparse_categorical_accuracy : 0.8881\n",
      " => val_loss : 0.3147\n",
      "Results of epoch 2:\n",
      " => sparse_categorical_accuracy : 0.8755\n",
      " => loss : 0.3350\n",
      " => val_sparse_categorical_accuracy : 0.8852\n",
      " => val_loss : 0.3221\n",
      "Results of epoch 3:\n",
      " => sparse_categorical_accuracy : 0.8785\n",
      " => loss : 0.3290\n",
      " => val_sparse_categorical_accuracy : 0.8873\n",
      " => val_loss : 0.3151\n",
      "Results of epoch 4:\n",
      " => sparse_categorical_accuracy : 0.8793\n",
      " => loss : 0.3252\n",
      " => val_sparse_categorical_accuracy : 0.8898\n",
      " => val_loss : 0.3110\n",
      "Results of epoch 5:\n",
      " => sparse_categorical_accuracy : 0.8808\n",
      " => loss : 0.3209\n",
      " => val_sparse_categorical_accuracy : 0.8924\n",
      " => val_loss : 0.3062\n",
      "Results of epoch 6:\n",
      " => sparse_categorical_accuracy : 0.8820\n",
      " => loss : 0.3186\n",
      " => val_sparse_categorical_accuracy : 0.8924\n",
      " => val_loss : 0.3097\n",
      "Results of epoch 7:\n",
      " => sparse_categorical_accuracy : 0.8817\n",
      " => loss : 0.3160\n",
      " => val_sparse_categorical_accuracy : 0.8919\n",
      " => val_loss : 0.3105\n",
      "Results of epoch 8:\n",
      " => sparse_categorical_accuracy : 0.8856\n",
      " => loss : 0.3115\n",
      " => val_sparse_categorical_accuracy : 0.8908\n",
      " => val_loss : 0.3074\n",
      "Results of epoch 9:\n",
      " => sparse_categorical_accuracy : 0.8856\n",
      " => loss : 0.3104\n",
      " => val_sparse_categorical_accuracy : 0.8925\n",
      " => val_loss : 0.3038\n",
      "Results of epoch 10:\n",
      " => sparse_categorical_accuracy : 0.8855\n",
      " => loss : 0.3070\n",
      " => val_sparse_categorical_accuracy : 0.8928\n",
      " => val_loss : 0.3104\n",
      "/n Time taken for training : 121.10333752632141\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "    loss_tracking_metric.reset_states()\n",
    "    \n",
    "    for inputs_batch , labels_batch in training_data:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(inputs_batch , training = True)\n",
    "            loss = loss_fn(labels_batch , predictions)\n",
    "        gradients = tape.gradient(loss , model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients , model.trainable_weights))\n",
    "    \n",
    "        logs = {}\n",
    "        for metric in metrics:\n",
    "            metric.update_state(labels_batch , predictions)\n",
    "            logs[metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"loss\"] = loss_tracking_metric.result()\n",
    "        \n",
    "    for metric in metrics:\n",
    "        metric.reset_states()\n",
    "    loss_tracking_metric.reset_states()\n",
    "        \n",
    "    for val_inputs_batch , val_label_batch in validation_data:\n",
    "        predictions = model(val_inputs_batch , training = False)\n",
    "        loss = loss_fn(val_label_batch , predictions)\n",
    "        for metric in metrics:\n",
    "            metric.update_state(val_label_batch , predictions)\n",
    "            logs[\"val_\" + metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "            \n",
    "        \n",
    "    print(f\"Results of epoch {epoch + 1}:\")\n",
    "    for key , value in logs.items():\n",
    "        print(f\" => {key} : {value:.4f}\")\n",
    "        \n",
    "end_time = time.time()\n",
    "print(\"Time taken for training :\" , end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "443b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_resetting():\n",
    "    for metric in  metrics:\n",
    "        metric.reset_states()\n",
    "    loss_tracking_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a8b9153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updating_logs(labels , preds, loss , is_training):\n",
    "    if is_training:\n",
    "        for metric in metrics:\n",
    "            metric.update_state(labels , preds)\n",
    "            logs[metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"loss\"] = loss_tracking_metric.result()\n",
    "        \n",
    "    else:\n",
    "        for metric in metrics:\n",
    "            metric.update_state(labels , preds)\n",
    "            logs[\"val_\" + metric.name] = metric.result()\n",
    "        loss_tracking_metric.update_state(loss)\n",
    "        logs[\"val_loss\"] = loss_tracking_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a126cb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_iteration(inputs,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs , training = True)\n",
    "        loss = loss_fn(labels , predictions)\n",
    "    gradients = tape.gradient(loss , model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients , model.trainable_weights))\n",
    "    return predictions , loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "43703882",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def validation_iteration(inputs,labels):\n",
    "    predictions = model(inputs , training = False)\n",
    "    loss = loss_fn(labels , predictions)\n",
    "    return predictions , loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2cb86aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of epoch 1:\n",
      " => sparse_categorical_accuracy : 0.8687\n",
      " => loss : 0.3525\n",
      " => val_sparse_categorical_accuracy : 0.8810\n",
      " => val_loss : 0.3267\n",
      "Results of epoch 2:\n",
      " => sparse_categorical_accuracy : 0.8709\n",
      " => loss : 0.3494\n",
      " => val_sparse_categorical_accuracy : 0.8804\n",
      " => val_loss : 0.3284\n",
      "Results of epoch 3:\n",
      " => sparse_categorical_accuracy : 0.8725\n",
      " => loss : 0.3474\n",
      " => val_sparse_categorical_accuracy : 0.8848\n",
      " => val_loss : 0.3217\n",
      "Results of epoch 4:\n",
      " => sparse_categorical_accuracy : 0.8733\n",
      " => loss : 0.3423\n",
      " => val_sparse_categorical_accuracy : 0.8826\n",
      " => val_loss : 0.3274\n",
      "Results of epoch 5:\n",
      " => sparse_categorical_accuracy : 0.8749\n",
      " => loss : 0.3344\n",
      " => val_sparse_categorical_accuracy : 0.8827\n",
      " => val_loss : 0.3200\n",
      "Results of epoch 6:\n",
      " => sparse_categorical_accuracy : 0.8763\n",
      " => loss : 0.3330\n",
      " => val_sparse_categorical_accuracy : 0.8840\n",
      " => val_loss : 0.3252\n",
      "Results of epoch 7:\n",
      " => sparse_categorical_accuracy : 0.8765\n",
      " => loss : 0.3326\n",
      " => val_sparse_categorical_accuracy : 0.8877\n",
      " => val_loss : 0.3139\n",
      "Results of epoch 8:\n",
      " => sparse_categorical_accuracy : 0.8765\n",
      " => loss : 0.3312\n",
      " => val_sparse_categorical_accuracy : 0.8886\n",
      " => val_loss : 0.3120\n",
      "Results of epoch 9:\n",
      " => sparse_categorical_accuracy : 0.8792\n",
      " => loss : 0.3248\n",
      " => val_sparse_categorical_accuracy : 0.8833\n",
      " => val_loss : 0.3214\n",
      "Results of epoch 10:\n",
      " => sparse_categorical_accuracy : 0.8803\n",
      " => loss : 0.3204\n",
      " => val_sparse_categorical_accuracy : 0.8877\n",
      " => val_loss : 0.3154\n",
      "Time taken for training : 55.96880745887756\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    metrics_resetting()\n",
    "    logs = {}\n",
    "    \n",
    "    for inputs_batch , labels_batch in training_data:\n",
    "        predictions , loss = training_iteration(inputs_batch , labels_batch)\n",
    "        updating_logs(labels_batch , predictions , loss , True)\n",
    "        \n",
    "    metrics_resetting()\n",
    "        \n",
    "    for val_inputs_batch , val_labels_batch in validation_data:\n",
    "        predictions , loss = validation_iteration(val_inputs_batch , val_labels_batch)    \n",
    "        updating_logs(val_labels_batch , predictions , loss , False)\n",
    "        \n",
    "    print(f\"Results of epoch {epoch + 1}:\")\n",
    "    for key , value in logs.items():\n",
    "        print(f\" => {key} : {value:.4f}\")\n",
    "        \n",
    "end_time = time.time()\n",
    "print(\"Time taken for training :\" , end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cc65de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions) \n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions) \n",
    "        return {m.name: m.result() for m in self.metrics} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d1a2a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28,28))\n",
    "flatten = keras.layers.Flatten()(inputs)\n",
    "x = keras.layers.Dense(512 , activation = \"relu\")(flatten)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(100 , activation = \"relu\")(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output = keras.layers.Dense(10 , activation = \"softmax\")(x)\n",
    "model = CustomModel(inputs , output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2f69b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6331 - sparse_categorical_accuracy: 0.7936 - val_loss: 0.4403 - val_sparse_categorical_accuracy: 0.8393\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4824 - sparse_categorical_accuracy: 0.8246 - val_loss: 0.3976 - val_sparse_categorical_accuracy: 0.8538\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4458 - sparse_categorical_accuracy: 0.8377 - val_loss: 0.3823 - val_sparse_categorical_accuracy: 0.8609\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4225 - sparse_categorical_accuracy: 0.8439 - val_loss: 0.3678 - val_sparse_categorical_accuracy: 0.8646\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4122 - sparse_categorical_accuracy: 0.8500 - val_loss: 0.3614 - val_sparse_categorical_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3986 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.8731\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3879 - sparse_categorical_accuracy: 0.8562 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3809 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.3342 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3762 - sparse_categorical_accuracy: 0.8629 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8823\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3677 - sparse_categorical_accuracy: 0.8643 - val_loss: 0.3336 - val_sparse_categorical_accuracy: 0.8801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ef840d7c10>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer ,\n",
    "             loss = loss_fn,\n",
    "             metrics= metrics)\n",
    "model.fit(X_train , y_train , batch_size=32 , epochs=10 ,\n",
    "         validation_data=(X_val , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded1410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
